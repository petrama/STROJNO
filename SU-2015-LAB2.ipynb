{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "# Strojno učenje\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>\n",
    "\n",
    "Ak. god. 2015./2016.\n",
    "\n",
    "# Laboratorijska vježba 2: Regresija i perceptron\n",
    "# Studentica: Petra Marče (0036473653)\n",
    "\n",
    "\n",
    "(c) 2015 Jan Šnajder\n",
    "\n",
    "*Verzija 0.2*\n",
    "\n",
    "Objavljeno: **10. studenog 2015.**<br>\n",
    "Rok za predaju: **16-20. studenog 2015.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upute\n",
    "\n",
    "Laboratorijska vježba 2 sastoji se od deset zadataka. U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg koda te evaluiranja ćelija. Odgovore na pitanja **nemojte pisati** u bilježnicu koju ćete demonstrirati asistentu (kako ih pri predaji ne bi samo čitali).\n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kod koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta preinačiti i ponovno evaluirati Vaš kod. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Stoga se nemojte ograničiti samo na to da riješite zadatak, već slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['linalg', 'poly']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Univarijatna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matrixom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25]\n",
      " [ 0.5 ]\n",
      " [ 1.  ]\n",
      " [ 1.5 ]\n",
      " [ 2.  ]]\n",
      "[ 0.707  1.     0.    -1.     0.   ]\n"
     ]
    }
   ],
   "source": [
    "X = sp.array([[0.25],[0.5],[1],[1.5],[2]])\n",
    "y = sp.array([0.707,1,0,-1,0])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz bilbioteke sklearn i upotrijebite je za generiranje dizajn-matrice $\\mathbf{\\Phi}$ sa $m=n$. Drugim riječima, generirajte dizajn-matricu bez preslikavanja u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   2.50000000e-01,   6.25000000e-02,\n",
       "          1.56250000e-02,   3.90625000e-03,   9.76562500e-04],\n",
       "       [  1.00000000e+00,   5.00000000e-01,   2.50000000e-01,\n",
       "          1.25000000e-01,   6.25000000e-02,   3.12500000e-02],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   1.50000000e+00,   2.25000000e+00,\n",
       "          3.37500000e+00,   5.06250000e+00,   7.59375000e+00],\n",
       "       [  1.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n",
       "          8.00000000e+00,   1.60000000e+01,   3.20000000e+01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly=PolynomialFeatures(5)\n",
    "fi=poly.fit_transform(X)\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ dizajn-matrice, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -0.59960179,   7.44307556, -10.43861011,   3.2770166 ,\n",
       "          0.38099121,  -0.15445908]),\n",
       " array([-0.30719283,  5.3844748 , -4.67183873, -3.47752447,  3.89130035,\n",
       "        -0.81921911]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "fitr=fi.transpose()\n",
    "w=inv(fitr.dot(fi)).dot(fitr).dot(y)\n",
    "w2=pinv(fi).dot(y)\n",
    "w,w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{x}}^{(i)} - h(\\tilde{\\mathbf{x}}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6) (6,)\n",
      "0.00698892596178 0.0174723149045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def h(x,w):  return sp.dot(x,w)\n",
    "pred=h(fi,w)\n",
    "k=array([w])\n",
    "print(fi.shape,w.shape)\n",
    "def ql(gt,dt):\n",
    "    return sum((dt-gt)**2)/2\n",
    "u=mean_squared_error(y,pred)\n",
    "m=ql(y,pred)\n",
    "print(u,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadrante pogreške nisu posve identične. U čemu je razlika? Koja je funkcija korisnija u praksi? Zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w=inv(fi).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Uvjerite se da su težine koje izračunava ta funkcija (dostupne pomoću metoda `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865887706998 [ 0.         -0.1646806  -0.29200238 -0.34611471 -0.24308637  0.22550793]\n",
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyYwkfiGESGb+D4CyZaqGpTtUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x83c38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "regr=Ridge(1)\n",
    "regr.fit(fi,y)\n",
    "print(regr.intercept_,regr.coef_)\n",
    "\n",
    "\n",
    "rez=regr.predict(fi)\n",
    "mean_squared_error(pred,y)\n",
    "\n",
    "def h(x,w):\n",
    "    return sp.dot(x,w)\n",
    "\n",
    "print(X.shape)\n",
    "plt.plot(X,y)\n",
    "xxx=linspace(0.5,1.5)\n",
    "ysin=sin(xxx*sp.pi)\n",
    "\n",
    "plt.plot(xxx,ysin)\n",
    "plt.plot(X,rez)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (50,50,3) and (6,) not aligned: 3 (dim 2) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-970fa263033f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mXY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e86e97b7affe>\u001b[0m in \u001b[0;36mh\u001b[1;34m(x, w)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,50,3) and (6,) not aligned: 3 (dim 2) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "x=linspace(0,10)\n",
    "y=x\n",
    "\n",
    "XX,Y= meshgrid(x,y)\n",
    "XY=np.dstack((sp.ones((50,50)),XX,Y))\n",
    "print(XY.shape)\n",
    "plt.contour(XX,Y,h(XY,w),levels=[-1,0,1])\n",
    "plt.scatter(fi[0][1], fi[0][2], c='r')\n",
    "plt.scatter(fi[1][1], fi[1][2], c='g')\n",
    "plt.scatter(fi[2][1], fi[2][2], c='b')\n",
    "plt.scatter(fi[3][1], fi[3][2], c='r')\n",
    "plt.scatter(fi[4][1], fi[4][2], c='g')\n",
    "print(h([1,1,1],w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$.\n",
    "\n",
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "def labels(X,f,noise=1):\n",
    "    y=array([f(x)+normal(0,noise) for x in X])\n",
    "    return y\n",
    "X=np.array([linspace(-5,5,50)])\n",
    "X=X.T\n",
    "def fja(x): return 5+x-2*x*x-5*x*x*x\n",
    "y=labels(X,fja,200)\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def phi(x): return array([1,x,x**2,x**3])\n",
    "dizajn=array([phi(x) for x in X])\n",
    "print(dizajn)\n",
    "w=pinv(dizajn).dot(y)\n",
    "print(w)\n",
    "pred=h(dizajn,w)\n",
    "g=mean_squared_error(pred,y)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly3=PolynomialFeatures(3)\n",
    "diz=poly3.fit_transform(X)\n",
    "regr.fit(diz,y)\n",
    "print(regr.intercept_)\n",
    "print(regr.coef_)\n",
    "pred2=regr.predict(diz)\n",
    "g2=mean_squared_error(pred2,y)\n",
    "print(g2)\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X,pred2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [1,3,5,10,20]:\n",
    "    poly=PolynomialFeatures(d)\n",
    "    diz=poly.fit_transform(X)\n",
    "\n",
    "    regr.fit(diz,y)\n",
    "    pred=regr.predict(diz)\n",
    "    g2=mean_squared_error(pred,y)\n",
    "    plt.plot(X,pred,label=g2)\n",
    "    \n",
    "plt.scatter(X,y)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`cross_validation.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in\\{1,20\\}$. Radi preciznosti, funkcije $h(\\mathbf{x})$ iscrtajte na cijelom skupu primjera (ali pogrešku generalizacije računajte, naravno, samo na ispitnome skupu). Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih pet modela biti identična."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "X=np.array([[x] for x in linspace(-5,5,50)])\n",
    "y=labels(X,fja,200)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=cross_validation.train_test_split(X,y,test_size=0.5,random_state=17)\n",
    "regr=LinearRegression()\n",
    "degs=[r for r in range(1,21)]\n",
    "train_err=[k for k in zeros(len(degs))]\n",
    "test_err=[k for k in zeros(len(degs))]\n",
    "for i,d in enumerate(degs):\n",
    "    poly.degree=d\n",
    "    phi_train=poly.fit_transform(X_train)\n",
    "    phi_test=poly.fit_transform(X_test)\n",
    "    regr.fit(phi_train,y_train)\n",
    "    pred_train=regr.predict(phi_train)\n",
    "    pred_test=regr.predict(phi_test)\n",
    "    train_err[i]=mean_squared_error(pred_train,y_train);\n",
    "    test_err[i]=mean_squared_error(pred_test,y_test)\n",
    "    X_pom=np.union1d(X_train,X_test)\n",
    "    y_pom=np.union1d(pred_train,pred_test)\n",
    "    #plt.plot(X_pom,-y_pom)plt.show()\n",
    "\n",
    "plt.plot(degs,log(train_err))\n",
    "plt.plot(degs,log(test_err))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem s prethodnim eksperimentom jest stohastičnost koja je posljedica slučajne podjele primjera na primjere za učenje i primjere za ispitivanje. Jedan način da se to zaobiđe jest da se fiksira podjela skupa primjere. To, međutim, uvodi proizvoljnost i ne daje pouzdanu procjenu pogreške. Bolje rješenje jest ponoviti izračun više puta s različitim podjelama skupa podataka i zatim uprosječiti vrijednosti pogreške za svaki model. Definirajte funkciju `plot_poly_regression_errors(X, degrees, ratio=0.5, repeat=30)` koja radi upravo to: funkcija uzima matricu primjera `X` i vektor oznaka `y`, dijeli ih na skup za učenje i skup za ispitivanje u omjeru `ratio` (udio skupa za ispitivanje) te trenira polinomijalne regresijske modele svih stupnjeva iz liste `degrees`, i to svaki `repeat` puta, te prikazuje grafikon uprosječenih logaritama pogrešaka.\n",
    "\n",
    "**NB:**  Kako biste osigurali ponovljivost eksperimenta, generator pseudoslučajnih brojeva incijalizirajte nekom odabranom vrijednošću. Pritom osigurajte da svako ponavljanje eksperimenata ipak bude različito, ali da cjelokupan eksperiment bude ponovljiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_poly_regression_errors(X,degrees,ratio=0.5,repeat=30):\n",
    "    log_train_err=np.zeros(len(degrees))\n",
    "    log_test_err=np.zeros(len(degrees))\n",
    "    for r in range (0,repeat):\n",
    "        X_train,X_test,y_train,y_test=cross_validation.train_test_split(X,y,test_size=0.5,random_state=r)\n",
    "        for d in degrees:\n",
    "            poly=PolynomialFeatures(d)\n",
    "            diz=poly.fit_transform(X_train)\n",
    "            diz_test=poly.fit_transform(X_test)\n",
    "            regr.fit(diz,y_train)\n",
    "            predTrain=regr.predict(diz)\n",
    "            predTest=regr.predict(diz_test)\n",
    "            train_err=mean_squared_error(predTrain,y_train);\n",
    "            test_err=mean_squared_error(predTest,y_test)\n",
    "            log_train_err[d]+=log(train_err)\n",
    "            log_test_err[d]+=log(test_err)\n",
    "    \n",
    "   \n",
    "    log_train_err/=repeat\n",
    "    log_test_err/=repeat\n",
    "    plt.plot(degrees,log_train_err,label='train_err')\n",
    "    plt.plot(degrees,log_test_err,color='r',label='test_err')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plot_poly_regression_errors(X,range(0,20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za sve kombinacija broja primjera $N\\in\\{100,200,1000\\}$ i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera), zatim generirajte tri parova skupova za učenje i ispitivanje, svaki s različitom količinom šuma. Naposlijetku iz tih skupova izdvojite dodatne podskupove od $N=200$ primjera ($100$ za učenje i $100$ za ispitivanje) i $N=100$ primjera ($50$ za učenje i $50$ za ispitivanje)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.array([linspace(-5,5,1000)])\n",
    "X=X.T\n",
    "X=np.random.permutation(X)\n",
    "X_train=X[:500]\n",
    "X_test=X[500:]\n",
    "f, axarr = plt.subplots(3, 3)\n",
    "f.set_size_inches(15,10)\n",
    "for i,size in enumerate([1,0.4,0.5]):\n",
    "    n=len(X_train)*size\n",
    "    print(n)\n",
    "    X_train=np.random.permutation(X_train)[:n]\n",
    "    X_test=np.random.permutation(X_test)[:n]\n",
    "    for j,sigma in enumerate([100,200,500]):\n",
    "        y_train=labels(X_train,fja,sigma)\n",
    "        y_test=labels(X_test,fja,sigma)\n",
    "        train_err=zeros(20)\n",
    "        test_err=zeros(20)\n",
    "        degs=range(1,21)\n",
    "        for d in degs:\n",
    "            poly=PolynomialFeatures(d)\n",
    "            diz_train=poly.fit_transform(X_train)\n",
    "            diz_test=poly.fit_transform(X_test)\n",
    "            regr.fit(diz_train,y_train)\n",
    "            predTrain=regr.predict(diz_train)\n",
    "            predTest=regr.predict(diz_test)\n",
    "            train_err[d-1]=mean_squared_error(predTrain,y_train);\n",
    "            test_err[d-1]=mean_squared_error(predTest,y_test)\n",
    "        axarr[i,j].plot(degs,log(train_err),label='train_err')\n",
    "        axarr[i,j].plot(degs,log(test_err),color='r',label='test_err')\n",
    "        axarr[i,j].legend(loc='best')\n",
    "\n",
    "plt.show()\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "   # X=X.T\n",
    "    #def fja(x): return 5+x-2*x*x-5*x*x*x\n",
    "    #y=labels(X,fja,sigma)\n",
    "    #X_train,X_test,y_train,y_test=cross_validation.train_test_split(X,y,test_size=0.5,random_state=12)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sp.array([[0],[1],[2],[4]])\n",
    "y = sp.array([4,1,2,5])\n",
    "X,y\n",
    "poly=PolynomialFeatures(3)\n",
    "phi=poly.fit_transform(X)\n",
    "phiT=phi.transpose()\n",
    "for lam in [0,1,10]:\n",
    "    jedin=eye(len(phi))\n",
    "    jedin[0,0]=0\n",
    "    w=inv(phiT.dot(phi)+lam*jedin).dot(phiT).dot(y)\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (metode `coef_` i `intercept_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "for lam in [0,1,10]:\n",
    "    r=Ridge(lam)\n",
    "    print(r)\n",
    "    r.fit(phi,y)\n",
    "    print(r.intercept_)\n",
    "    print(r.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako te popravite izračun u zadatku 4a tako da težine budu identične ovima u zadatku 4b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regularizirana polinomijalna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=array([linspace(-5,5,50)])\n",
    "X=X.T\n",
    "brojac=0;\n",
    "y=labels(X,fja,200)\n",
    "plt.scatter(X,y)\n",
    "for d in [2,10]:\n",
    "    poly=PolynomialFeatures(d)\n",
    "    phi=poly.fit_transform(X)\n",
    "    for lam in  [0,100]:\n",
    "        r=Ridge(lam)\n",
    "        r.fit(phi,y)\n",
    "        pred_train=r.predict(phi)\n",
    "        train_err=mean_squared_error(pred_train,y)\n",
    "        \n",
    "        plt.plot(X,pred_train,label=train_err)\n",
    "        brojac+=1\n",
    "        print(train_err)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Jesu li rezultati očekivani? Obrazložite.\n",
    "\n",
    "**Q:** Za koji od ovih četiri modela biste očekivali da će najbolje generalizirati?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=20,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=cross_validation.train_test_split(X,y,test_size=0.5,random_state=101)\n",
    "d=20\n",
    "train_err=zeros(51)\n",
    "test_err=zeros(51)\n",
    "poly=PolynomialFeatures(d)\n",
    "phi_train=poly.fit_transform(X_train)\n",
    "phi_test=poly.fit_transform(X_test)\n",
    "for lam in range(0,51):\n",
    "    regr=Ridge(lam)\n",
    "    regr.fit(phi_train,y_train)\n",
    "    pred_train=regr.predict(phi_train)\n",
    "    pred_test=regr.predict(phi_test)\n",
    "    train_err[lam]=mean_squared_error(pred_train,y_train)\n",
    "    test_err[lam]=mean_squared_error(pred_test,y_test)\n",
    "plot(range(0,51),log(train_err))\n",
    "plot(range(0,51),log(test_err))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti a kojoj podnaučenosti. Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n",
    "\n",
    "**Q:** Jesu li rezultati stabilni? Zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcija:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[sp.isclose(0, coef, atol=tol)])\n",
    "def norm_l1(w):\n",
    "    return sum(abs(w))\n",
    "def norm_l2(w):\n",
    "    return norm(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=20$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "poly=PolynomialFeatures(20)\n",
    "phi_train=poly.fit_transform(X_train)\n",
    "phi_test=poly.fit_transform(X_test)\n",
    "lams=range(1,101)\n",
    "norms0=zeros(len(lams))\n",
    "norms1=zeros(len(lams))\n",
    "norms2=zeros(len(lams))\n",
    "for lam in lams:\n",
    "    regr=Ridge(lam)\n",
    "    regr.fit(phi_train,y_train)\n",
    "    w=regr.coef_[0]\n",
    "    norms0[lam-1]=nonzeroes(w)\n",
    "    norms1[lam-1]=norm_l1(w)\n",
    "    norms2[lam-1]=norm_l2(w)\n",
    "plt.plot(lams,log(norms0),label='L0')\n",
    "plt.plot(lams,log(norms1),label='L1')\n",
    "plt.plot(lams,log(norms2),label='L2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L1-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "poly=PolynomialFeatures(20)\n",
    "phi_train=poly.fit_transform(X_train)\n",
    "phi_test=poly.fit_transform(X_test)\n",
    "lams=range(1,101)\n",
    "norms0=zeros(len(lams))\n",
    "norms1=zeros(len(lams))\n",
    "norms2=zeros(len(lams))\n",
    "for lam in lams:\n",
    "    regr=Lasso(lam,max_iter=1000)\n",
    "    regr.fit(phi_train,y_train)\n",
    "    w=regr.coef_\n",
    "    norms0[lam-1]=nonzeroes(w)\n",
    "    norms1[lam-1]=norm_l1(w)\n",
    "    norms2[lam-1]=norm_l2(w)\n",
    "plt.plot(lams,norms0,label='L0')\n",
    "plt.plot(lams,norms1,label='L1')\n",
    "plt.plot(lams,norms2,label='L2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kojem biste modelu (Ridge ili LASSO) u praksi dali prednost, i zašto? U kojim situacijama je ta prednost osobito izražena?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *7. Predviđanje cijena nekretnina u Bostonu\n",
    "\n",
    "<span style=\"color:green\">(Rješavanje ovog zadatka nije obavezno, ali donosi dodatne bodove.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sada smo razmatrali isključivo univarijatnu regresiju, tj. imali smo samo jednu značajku ($n=1$). U većini stvarnih problema baratamo s većim brojem značajki. Razmotrimo sada jedan nešto realniji problem, kod kojega postoji više značajki, pa je potrebno napraviti multivarijatnu regresiju.\n",
    "\n",
    "Učitajte skup podataka *Boston House Prices*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)\n",
    "print(boston.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skup sadrži 506 primjera sa 13 numeričkih značajki. Opis skupa možete dobiti na sljedeći način:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš je zadatak da izgradite regresijski model za predviđanje cijene nekretnine (`y=boston.target`) na temelju 13 raspoloživih značajki za svaku nekretninu (`X=boston.data`). Cilj je pronaći najbolji mogući linearni model regresije na ovom skupu podataka i provjeriti njegovu točnost u smislu pogreške kvadratnog odstupanja ([`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)). \n",
    "\n",
    "Hiperparametri modela koje treba isprobati su:\n",
    "\n",
    "* **Regularizacija:** Bez regularizacije ([`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)), L2-regularizacija ([`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)) i L1-regularizacija ([`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso));\n",
    "* **Značajke:** Izvornih 13 značajki, polinomijalne značajke (isprobajte različite stupnjeve polinoma $d$), samo interakcijske značajke (opcija `interaction_only` u klasi [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html));\n",
    "* **Predobrada značajki:** Izvorne vrijednosti značajki ili standardizirane vrijednosti. Standardizacija je postupak skaliranja vrijednosti na distribuciju $\\mathcal{N}(0,1)$; v. [standard score](http://en.wikipedia.org/wiki/Standard_score). Koristite funkciju [`preprocessing.scale`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale).\n",
    "\n",
    "Kao i inače, za odabir i ispitivanje modela koristit ćemo **unakrsnu provjeru** (engl. *cross-validation*). Skup primjera za učenje podijelit ćemo na **skup za učenje**, **skup za provjeru** i **skup za ispitivanje** u omjeru (otprilike) 3:1:1. Kao u uvijek, model trebate trenirati na skupu za učenje, odabir modela (odnosno optimizaciju hiperparametra) trebate provesti na skupu za provjeru, a konačno vrednovanje modela trebate načiniti na skupu za ispitivanje. Konačno vrednovanje radite samo jednom, za model koji ste na skupu za provjeru odabrali kao optimalan.\n",
    "\n",
    "**NB:** Nakon što odaberete optimalan model na skupu za provjeru, prije konačnog ispitivanje odabrani model ponovno trenirajte na uniji skupova za učenje i ispitivanje. Na taj način iskorištavate maksimalno iskorištavate dostupne podatke i model će u pravilu biti bolji.\n",
    "\n",
    "Podjela na skup za učenje, provjeru i ispitivanje u ovom je slučaju fiksna kako bi svi imali identične skupove i kako bi rezultati bili usporedivi. (U stvarnosti biste ovakav eksperiment radili malo drugačije: koristili biste višestruku unakrsnu provjeru ili ugnježđenu unakrsnu provjeru. Više o tome reći ćemo u četvrtoj laboratorijskoj vježbi.) \n",
    "\n",
    "Koristite sljedeće skupove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "X_train, X_rest, y_train, y_rest = cross_validation.train_test_split(boston.data,boston.target,train_size=0.6,random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = cross_validation.train_test_split(X_rest,y_rest,test_size=0.5,random_state=42)\n",
    "print(X_train.shape,X_validate.shape ,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "d=10\n",
    "poly=PolynomialFeatures(d)\n",
    "p=poly.fit_transform(X_train)\n",
    "print('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear=LinearRegression()\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koliko značajki ima svaki od modela koji ste isprobali?\n",
    "\n",
    "**Q:** Koliko je zapravo dobar model koji ste trenirali? Bi li model bio dovoljno dobar za stvarnu uporabu? Možete li to odlučiti na temelju mjere srednjeg kvadratnog odstupanja, ili bi neki drugi pokazatelj bio korisniji?\n",
    "\n",
    "**Q:** Provjerite točnost odabranog modela na (1) skupu za učenje, (2) skupu za provjeru, (3) uniji ta dva skupa i (4) skupu za ispitivanje. Jesu li odnosi između točnosti modela na ova četiri skupa očekivana? Obrazložite.\n",
    "\n",
    "**Q:** Kod treniranja regresijskog modela moguće je postaviti `fit_intercept=False`, čime se izbjegava optimiranje težine $w_0$. Trenirajte odabrani model s tom postavkom. Usporedite s točnošću optimalnog modela. Je li rezultat očekivan? Obrazložite. Ima li predobrada značajki ikakvog utjecaja na ovu razliku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude težina $w_i$ upućuju na važnost odgovarajućih značajki $x_i$ u modelu. Načinite jednostavnu analizu značajki tako da ispišete rang-liste značajki s obzirom na težine. Analizu provedite nad modelom koji se u prethodnome zadatku pokazao optimalnim, tj. nad modelom koji ste u konačnici ispitivali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaše rješenje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Koje su top-3 značajke modela? Je li to očekivano? Obrazložite.\n",
    "\n",
    "**Q**: Kakve rezultate očekujete da biste dobili kada biste model trenirali samo s tih prvih tri značajki?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Linearna regresija kao klasifikator\n",
    "\n",
    "U nastavku vježbe bavimo se problemom **klasifikacije**.\n",
    "\n",
    "Klasifikacijske algoritme analizirat ćemo na skupu podataka `seven`, linearno odvojivom skupu podataka od $N=7$ primjera u $n=2$ dimenzije:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seven_X = sp.array([[2,1],[2,3],[1,2],[3,2],[5,2],[5,4],[6,3]])\n",
    "seven_y = sp.array([1,1,1,1,-1,-1,-1])\n",
    "print(seven_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija za vizualizaciju skupa podataka i granice između klasa (ako je zadana funkcija predikcije `h`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_problem(X, y, h=None, surfaces=True) :\n",
    "    '''\n",
    "    Plots a two-dimensional labeled dataset (X,y) and, if function h(x) is given, \n",
    "    the decision boundaries (surfaces=False) or decision surfaces (surfaces=True)\n",
    "    '''\n",
    "    assert X.shape[1] == 2, \"Dataset is not two-dimensional\"\n",
    "    if h!=None : \n",
    "        # Create a mesh to plot in\n",
    "        r = 0.02  # mesh resolution\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, r),\n",
    "                             np.arange(y_min, y_max, r))\n",
    "        XX=np.c_[xx.ravel(), yy.ravel()]\n",
    "        try:\n",
    "            Z_test = h(XX)\n",
    "            if shape(Z_test) == () :\n",
    "                # h returns a scalar when applied to a matrix; map explicitly\n",
    "                Z = sp.array(map(h,XX))\n",
    "            else :\n",
    "                Z = Z_test\n",
    "        except ValueError:\n",
    "            # can't apply to a matrix; map explicitly\n",
    "            Z = sp.array(map(h,XX))\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        if surfaces :\n",
    "            plt.contourf(xx, yy, Z, cmap=plt.cm.Pastel1)\n",
    "        else :\n",
    "            plt.contour(xx, yy, Z)\n",
    "    # Plot the dataset\n",
    "    scatter(X[:,0],X[:,1],c=y, cmap=plt.cm.Paired,marker='o',s=50);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_problem(seven_X,seven_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linearna regresija može se upotrijebiti za klasifikaciju tako da se nauči funkcija $f(\\mathbf{x})=+1$ za pozitivne primjere i $f(\\mathbf{x})=-1$ za negativne primjere. Granica između klasa u tom slučaju bit će funkcija $h(\\mathbf{x})=0$, tj. primjeri za koje $h(\\mathbf{x})\\geq 0$ klasificiraju se kao pozitivni, a ostali kao negativni.  \n",
    "\n",
    "### (a)\n",
    "\n",
    "Trenirajte model [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) na skupu `seven`, ispišite težine modela te prikažite primjere i granicu između klasa. Funkciju za predikciju, koju predajete kao treći argument funkcije `plot_problem`, možete definirati lambda-izrazom: `lambda x : model.predict(x) >= 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr=LinearRegression()\n",
    "regr.fit(seven_X,seven_y)\n",
    "plot_problem(seven_X,seven_y,(lambda x:regr.predict(x)>=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Ako bismo kao oznake umjesto $\\{+1,-1\\}$ koristili $\\{1,0\\}$, kako biste izračunali granicu između klasa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasifikacija pomoću linearne regresije implementirana je u klasi [`RidgeClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html). Pokažite da ta implementacija daje iste rezultate na skupu `seven` (pritom isključite regularizaciju, tj. postavite `alpha=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "klas=RidgeClassifier(alpha=0)\n",
    "klas.fit(seven_X,seven_y)\n",
    "plot_problem(seven_X,seven_y,(lambda x:klas.predict(x)>=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte klasifikacijski model `RidgeClassifier` na sljedećem skupu podataka (skup `seven` proširen jednim primjerom):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = sp.append(seven_X,[[2,2]],axis=0)\n",
    "y2 = sp.append(seven_y,-1)\n",
    "klas.fit(X2,y2)\n",
    "plot_problem(X2,y2,(lambda x:klas.predict(x)>=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite granicu između klasa te izračunajte točnost modela (možete koristiti funkciju [`metrics.accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def h(x, w): return sp.dot(x, w)\n",
    "\n",
    "def plot_decision_boundary(h, boundary=0, margins=None):\n",
    "    x = linspace(-10, 10)\n",
    "    y = linspace(-10, 10)\n",
    "    X1, X2 = np.meshgrid(x, y)\n",
    "    XX = sp.dstack((sp.ones((50, 50)), X1, X2))\n",
    "    plt.contour(X1, X2, h(XX), linecolor='red', levels=[boundary])\n",
    "    if margins!=None:\n",
    "        CS = plt.contour(X1, X2, h(XX), colors=['gray', 'gray'], levels=[margins[0],margins[1]])\n",
    "        plt.clabel(CS, fontsize=9, inline=1)\n",
    "\n",
    "w=[klas.intercept_[0]]\n",
    "w.extend(klas.coef_[0])\n",
    "plot_decision_boundary(lambda x : h(x, w), margins=(-1,1))\n",
    "plt.scatter\n",
    "pred=klas.predict(X2)\n",
    "acc=accuracy_score(pred,y2)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koliko iznosi točnost modela? Objasnite zašto model ne ostvaruje potpunu točnost. Je li problem u skupu podataka ili u modelu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte klasifikacijski model `RidgeClassifier` na sljedećem skupu podataka (skup `seven` proširen jednim primjerom):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3 = sp.append(seven_X,[[12,8]],axis=0)\n",
    "y3 = sp.append(seven_y,-1)\n",
    "\n",
    "klas.fit(X3,y3)\n",
    "plot_problem(X3,y3,(lambda x:klas.predict(x)>=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite granicu između klasa te izračunajte točnost modela."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def getw(klas):\n",
    "    w=[klas.intercept_[0]]\n",
    "    w.extend(klas.coef_[0])\n",
    "    return w\n",
    "\n",
    "plot_decision_boundary(lambda x : h(x, getw(klas)), margins=(-1,1))\n",
    "pred=klas.predict(X2)\n",
    "acc=accuracy_score(pred,y2)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koliko iznosi točnost modela? Objasnite zašto model ne ostvaruje potpunu točnost. Je li problem u skupu podataka ili u modelu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Višeklasna klasifikacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postoji više načina kako se binarni klasifikatori mogu se upotrijebiti za višeklasnu klasifikaciju. Najčešće se koristi shema tzv. **jedan-naspram-ostali** (engl. *one-vs-rest*, OVR), u kojoj se trenira po jedan klasifikator $h_j$ za svaku od $K$ klasa. Svaki klasifikator $h_j$ trenira se da razdvaja primjere klase $j$ od primjera svih drugih klasa, a primjer se klasificira u klasu $j$ za koju je $h_j(\\mathbf{x})$ maksimalan.\n",
    "\n",
    "Pomoću funkcije [`datasets.make_classification`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) generirajte slučajan skup podataka od tri klase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "#X, y =make_classification(n_features=2,n_classes=3,n_informative=2,n_redundant=0,n_clusters_per_class=1)\n",
    "X=sp.array([[-3,1],[-3,3],[1,2],[2,1],[1,-2],[2,-3]])\n",
    "print(X)\n",
    "y=np.array([0,0,1,1,2,2])\n",
    "reg=Ridge(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [ 5 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-133ad9150baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0myi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mw0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mw0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Petra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Petra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=np.float,\n\u001b[1;32m--> 382\u001b[1;33m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[1;32mC:\\Users\\Petra\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Petra\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[1;32m--> 174\u001b[1;33m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [ 5 50]"
     ]
    }
   ],
   "source": [
    "for z in range(0,3):\n",
    "    yi=y.copy()\n",
    "    for i,k in enumerate(yi):\n",
    "        if k==z:\n",
    "            yi[i]=1\n",
    "        else:\n",
    "            yi[i]=0\n",
    "    reg.fit(X,yi)\n",
    "    w0=[reg.intercept_]\n",
    "    w0.extend(reg.coef_)\n",
    "    print(w0)\n",
    "    plot_problem(X,y)\n",
    "    plot_decision_boundary(lambda x : h(x, w0),0.5,margins=[0.25,0.75])\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte tri binarna klasifikatora, $h_1$, $h_2$ i $h_3$ te prikažite granice između klasa (tri grafikona). Zatim definirajte $h(\\mathbf{x})=\\mathrm{argmax}_j h_j(\\mathbf{x})$ i prikažite granice između klasa za taj model. Zatim se uvjerite da biste identičan rezultat dobili izravno primjenom modela `RidgeClassifier`, budući da taj model za višeklasan problem zapravo interno implementira shemu jedan-naspram-ostali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classif = OneVsRestClassifier(reg)\n",
    "classif.fit(X, y)\n",
    "classif.predict(X)\n",
    "lista=classif.estimators_\n",
    "for hi in lista:\n",
    "    w=[hi.intercept_]\n",
    "    w.extend(hi.coef_)\n",
    "    print(w)\n",
    "    plot_decision_boundary(lambda x : h(x,w),0.5,margins=[0.25,0.75])\n",
    "    plot_problem(X,y)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Alternativna shema je one-vs-one (OVO). Koja je prednost sheme OVR nad shemom OVO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pravi(hipoteze,primjer):\n",
    "    for h in hipoteze:\n",
    "        print(h.predict(primjer))\n",
    "\n",
    "print(X[1])\n",
    "pravi(lista,X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron je implementiran klasom [`linear_model.Perceptron`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html). Trenirajte perceptron na skupu `seven` iz zadatka 8a i prikažite granicu između klasa. Uvjerite se da rezultat ovisi o redoslijedu primjera u skupu za učenje (postavite `shuffle=True` i mijenjajte parametar `random_state`). Zatim trenirajte perceptron na dvama varijantima skupa `seven` iz zadataka 8b i 8c te prikažite opet granice između klasa.\n",
    "\n",
    "**NB:** Obratite pozornost na broj iteracija algoritma (parametar `n_iter`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "for t in [(seven_X,seven_y),(X2,y2),(X3,y3)]:\n",
    "    for s in [5,101,437,888]:\n",
    "        p=Perceptron(n_iter=10000,random_state=s)\n",
    "        p.fit(t[0],t[1])\n",
    "        p.coef_\n",
    "        p.intercept_\n",
    "        w=[p.intercept_[0]]\n",
    "        w.extend(p.coef_[0])\n",
    "        plot_problem(t[0],t[1],lambda x: p.predict(x))\n",
    "        #plot_decision_boundary(lambda x : h(x,w))\n",
    "        #plt.title('w='+str(w))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Komentirajte razlike u rezultatima dobivenima na skupu `seven` i na dvije njegove varijante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
